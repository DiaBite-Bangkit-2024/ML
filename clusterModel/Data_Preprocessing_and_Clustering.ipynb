{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61SWU7D1cSMr"
   },
   "source": [
    "# DiaBite : Product Based Capstone Project\n",
    "This Colab is for preprocessing datasets and making cluster for food suggestion using sklearn, pandas, numpy, and matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XTtNN22Jfrj3"
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "\n",
    "%pip install gdown\n",
    "\n",
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D6ax5iXYfq-q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import gdown\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssNLVG9FcaFs"
   },
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory tree of your workspace should be like this:\n",
    "\n",
    "workspace\n",
    "```\n",
    "|-- Data_Preprocessing_and_Clustering.ipynb\n",
    "|-- dataset/\n",
    "    |-- diabetes-dataset.csv\n",
    "    |-- FOOD-DATA-GROUP1.csv\n",
    "    |-- FOOD-DATA-GROUP2.csv\n",
    "    |-- FOOD-DATA-GROUP3.csv\n",
    "    |-- FOOD-DATA-GROUP4.csv\n",
    "    |-- FOOD-DATA-GROUP5.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dl6EWUrxe6RR"
   },
   "source": [
    "### Download Dataset From Drive (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this following code if you not have the dataset yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qYBr8caucPUy"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"dataset\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lOQZWac9OPk6",
    "outputId": "376066e6-b82b-43dd-945b-b5f73bddb45c"
   },
   "outputs": [],
   "source": [
    "# download foods dataset\n",
    "gdown.download_folder(\"https://drive.google.com/drive/folders/1l6UEQH04_Lx6mwklnnvwWHmpk2bo45p9?usp=sharing\", quiet=True, use_cookies=False, output=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "v9mJOud_e9gw",
    "outputId": "38947ad6-b1b5-46c4-882e-ad859cb142bb"
   },
   "outputs": [],
   "source": [
    "# download file diabetes dataset\n",
    "gdown.download('https://drive.google.com/file/d/1DuG0W9gF74BvXNuied2YhU1VOvZq53sS/view?usp=drive_link', output='dataset/diabetes-dataset.csv', quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-hpa8849fiJu"
   },
   "source": [
    "### Gather Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KuL5kMkfmRa",
    "outputId": "a322277f-fb90-48c9-94ad-e15e654cb98d"
   },
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv(\"dataset/diabetes-dataset.csv\")\n",
    "diabetes_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgNuOX2gh1hs"
   },
   "source": [
    "### Gather Food Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koaff7N9h_v2"
   },
   "outputs": [],
   "source": [
    "foods_df = [\n",
    "  pd.read_csv(\"dataset/FOOD-DATA-GROUP1.csv\"),\n",
    "  pd.read_csv(\"dataset/FOOD-DATA-GROUP2.csv\"),\n",
    "  pd.read_csv(\"dataset/FOOD-DATA-GROUP3.csv\"),\n",
    "  pd.read_csv(\"dataset/FOOD-DATA-GROUP4.csv\"),\n",
    "  pd.read_csv(\"dataset/FOOD-DATA-GROUP5.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Method 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'dataset'\n",
    "\n",
    "temp_foods_df = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.lower().startswith(\"food-data\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the CSV file and append to the list\n",
    "        df = pd.read_csv(file_path)\n",
    "        temp_foods_df.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "foods_df = [pd.concat(temp_foods_df, ignore_index=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zve9-6yle8z"
   },
   "source": [
    "## Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uVDTG8tnrUjU"
   },
   "source": [
    "### Cleaning Diabetes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RwuqBP7ipBrG",
    "outputId": "6f6be434-7de3-4af5-956e-41017e340bc2"
   },
   "outputs": [],
   "source": [
    "# print dataset informations\n",
    "print(diabetes_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "liiocWoCmdT7",
    "outputId": "9a24dfc9-0d0f-4335-8c77-5782c8cafa61"
   },
   "outputs": [],
   "source": [
    "#check total rows\n",
    "print(\"total rows : \", len(diabetes_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AyzCahwllLz",
    "outputId": "17a70886-a675-436b-9e1a-6c52280f716f"
   },
   "outputs": [],
   "source": [
    "# Check missing value(s)\n",
    "missing_values = diabetes_df[['GenHlth', 'HighBP', 'BMI', 'DiffWalk', 'HighChol', 'Age', 'HeartDiseaseorAttack', 'PhysHlth', 'Stroke', 'MentHlth']].isnull().sum()\n",
    "print(\"Missing values per column:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YWYeSITep3i8",
    "outputId": "63684077-4cc1-475d-caa7-6aad0ef3ff2e"
   },
   "outputs": [],
   "source": [
    "# handle outliers for the dataset BMI\n",
    "Q1 = diabetes_df['BMI'].quantile(0.25)\n",
    "Q3 = diabetes_df['BMI'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "diabetes_df_filtered = diabetes_df[~((diabetes_df['BMI'] < lower_bound) | (diabetes_df['BMI'] > upper_bound))]\n",
    "# Calculate the median of the BMI\n",
    "median_bmi = diabetes_df['BMI'].median()\n",
    "# Replace the outliers with the median\n",
    "diabetes_df['BMI'] = np.where(((diabetes_df['BMI'] < lower_bound) | (diabetes_df['BMI'] > upper_bound)), median_bmi, diabetes_df['BMI'])\n",
    "\n",
    "print(diabetes_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_u_vx01vrctD"
   },
   "source": [
    "### Cleaning Food Dataset(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df):\n",
    "    # Fitur: Total Nutrition\n",
    "    foods_df[i]['Total_Nutrition'] = foods_df[i][['Carbohydrates', 'Protein', 'Dietary Fiber', \n",
    "      'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats', 'Vitamin D', \n",
    "      'Magnesium', 'Potassium']].sum(axis=1)\n",
    "    \n",
    "    # Fitur: Nutrition Density\n",
    "    foods_df[i]['Nutrition_Density'] = foods_df[i]['Total_Nutrition'] / foods_df[i]['Caloric Value']\n",
    "\n",
    "    # Fitur: Glycemic Load\n",
    "    if 'Glycemic Index' in foods_df[i].columns:\n",
    "        foods_df[i]['Glycemic_Load'] = (foods_df[i]['Glycemic Index'] * foods_df[i]['Carbohydrates']) / 100\n",
    "    else:\n",
    "        print(f\"Dataset {i}: Kolom 'Glycemic Index' tidak tersedia. Skip fitur Glycemic Load.\")\n",
    "\n",
    "    # Fitur: Macronutrient Ratios\n",
    "    if 'Fat' in foods_df[i].columns:\n",
    "        foods_df[i]['Protein_Ratio'] = (foods_df[i]['Protein'] * 4) / foods_df[i]['Caloric Value']\n",
    "        foods_df[i]['Carbohydrate_Ratio'] = (foods_df[i]['Carbohydrates'] * 4) / foods_df[i]['Caloric Value']\n",
    "        foods_df[i]['Fat_Ratio'] = (foods_df[i]['Fat'] * 9) / foods_df[i]['Caloric Value']\n",
    "    else:\n",
    "        print(f\"Dataset {i}: Kolom 'Fat' tidak tersedia. Skip fitur Macronutrient Ratios.\")\n",
    "\n",
    "    # Fitur: Nutrient-to-Calorie Ratio\n",
    "    foods_df[i]['Micronutrient_Sum'] = foods_df[i][['Vitamin D', 'Magnesium', 'Potassium']].sum(axis=1)\n",
    "    foods_df[i]['Nutrient_to_Calorie'] = foods_df[i]['Micronutrient_Sum'] / foods_df[i]['Caloric Value']\n",
    "\n",
    "    # Fitur: Fiber-to-Sugar Ratio\n",
    "    foods_df[i]['Fiber_to_Sugar_Ratio'] = foods_df[i]['Dietary Fiber'] / foods_df[i]['Sugars']\n",
    "\n",
    "    # Fitur: Saturated Fat Ratio\n",
    "    if 'Fat' in foods_df[i].columns:\n",
    "        foods_df[i]['Saturated_Fat_Ratio'] = foods_df[i]['Saturated Fats'] / foods_df[i]['Fat']\n",
    "    else:\n",
    "        print(f\"Dataset {i}: Kolom 'Fat' tidak tersedia. Skip fitur Saturated Fat Ratio.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q4dPAal2rfuR",
    "outputId": "6359308c-2310-4c18-f63e-29a83452f291"
   },
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df) :\n",
    "  print(food_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUSxhJHGS1bH",
    "outputId": "2fef06df-342c-463f-b1b8-ebdd5f299e34"
   },
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df) :\n",
    "  # Cek apakah ada nilai NaN\n",
    "  print(\"Jumlah NaN di setiap kolom:\")\n",
    "  print(foods_df[i].isna().sum())\n",
    "\n",
    "  # Cek apakah ada nilai inf atau -inf\n",
    "  print(\"Apakah ada nilai inf atau -inf?\")\n",
    "  print((foods_df[i] == float('inf')).any().any(), (foods_df[i] == float('-inf')).any().any())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temukan kolom dengan nilai inf\n",
    "for i, food_df in enumerate(foods_df) :\n",
    "  inf_cols = foods_df[i].columns[(foods_df[i] == float('inf')).any()]\n",
    "  print(f\"Kolom dengan nilai inf: {inf_cols}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris dengan NaN\n",
    "for i, food_df in enumerate(foods_df) :\n",
    "  foods_df[i].dropna(subset=['Nutrition_Density', 'Protein_Ratio', 'Carbohydrate_Ratio', 'Fat_Ratio',\n",
    "                            'Nutrient_to_Calorie', 'Fiber_to_Sugar_Ratio', 'Saturated_Fat_Ratio'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris dengan nilai inf\n",
    "for i, food_df in enumerate(foods_df) :\n",
    "  foods_df[i] = foods_df[i][~(foods_df[i] == float('inf')).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df) :\n",
    "  foods_df[i].drop([\"Unnamed: 0.1\",\"Unnamed: 0\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df) :\n",
    "  temp_food_df = foods_df[i].drop(columns=[\"food\"])\n",
    "  correlation_matrix = temp_food_df.corr(method='pearson')\n",
    "\n",
    "  plt.figure(figsize=(20, 8))\n",
    "  sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "  plt.title(\"Heatmap Korelasi Fitur\")\n",
    "  plt.show()\n",
    "\n",
    "  threshold = 0.8\n",
    "  redundant_features = []\n",
    "  for i in range(len(correlation_matrix.columns)):\n",
    "      for j in range(i + 1, len(correlation_matrix.columns)):\n",
    "          if abs(correlation_matrix.iloc[i, j]) > threshold:\n",
    "              feature_1 = correlation_matrix.columns[i]\n",
    "              feature_2 = correlation_matrix.columns[j]\n",
    "              redundant_features.append((feature_1, feature_2, correlation_matrix.iloc[i, j]))\n",
    "\n",
    "  print(\"Fitur-fitur dengan korelasi tinggi (redundan):\")\n",
    "  for feature_1, feature_2, corr in redundant_features:\n",
    "      print(f\"{feature_1} - {feature_2}: korelasi = {corr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G-S9BAuS9Id"
   },
   "source": [
    "## Clustering Food Dataset(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hhU5RXNkTC2p"
   },
   "source": [
    "### Using sklearn K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qSudjzgXU36r"
   },
   "outputs": [],
   "source": [
    "# features used to clustering\n",
    "food_indices = ['Caloric Value', 'Carbohydrates', 'Sugars', 'Dietary Fiber',\n",
    " 'Saturated Fats', 'Monounsaturated Fats', 'Polyunsaturated Fats',\n",
    " 'Protein', 'Vitamin D', 'Magnesium', 'Potassium']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features used to clustering\n",
    "food_indices = [\n",
    "    'Caloric Value',\n",
    "    'Carbohydrates',\n",
    "    'Sugars',\n",
    "    'Dietary Fiber',\n",
    "    'Protein',\n",
    "    'Vitamin D', \n",
    "    'Magnesium',\n",
    "    'Potassium'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_indices = [\n",
    "    'Caloric Value', 'Carbohydrates', 'Sugars', 'Protein', 'Dietary Fiber', 'Saturated Fats', \n",
    "    'Monounsaturated Fats', 'Polyunsaturated Fats', 'Vitamin D', \n",
    "    'Magnesium', 'Potassium', 'Nutrition_Density',\n",
    "    'Protein_Ratio', 'Carbohydrate_Ratio', 'Fat_Ratio',\n",
    "    'Nutrient_to_Calorie', 'Fiber_to_Sugar_Ratio', 'Saturated_Fat_Ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "egrIoVcZqjh1"
   },
   "outputs": [],
   "source": [
    "# making scaler of the data\n",
    "scaler = StandardScaler()\n",
    "foods_scaled = [scaler.fit_transform(food_df[food_indices]) for food_df in foods_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeSOtV6dTTMA"
   },
   "outputs": [],
   "source": [
    "# making PCA for each food dataset\n",
    "pca = PCA(n_components=2)\n",
    "foods_pca = [pca.fit_transform(food_scaled) for food_scaled in foods_scaled]\n",
    "\n",
    "for i, food_df in enumerate(foods_df) :\n",
    "  foods_df[i]['PCA1'] = foods_pca[i][:, 0]\n",
    "  foods_df[i]['PCA2'] = foods_pca[i][:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iXwPdT-6TIX9",
    "outputId": "b34c77f3-0cbb-4988-c238-8360a4729774"
   },
   "outputs": [],
   "source": [
    "# Elbow\n",
    "sses = []\n",
    "\n",
    "for food_scaled in foods_scaled:\n",
    "  sse = []\n",
    "  for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(food_scaled)\n",
    "    sse.append(kmeans.inertia_)\n",
    "    # print(sse)\n",
    "\n",
    "  sses.append(sse)\n",
    "\n",
    "# print(sses)\n",
    "\n",
    "for i, sse in enumerate(sses) :\n",
    "  plt.figure(figsize=(8, 5))\n",
    "  plt.plot(range(1, 11), sse, marker='o')\n",
    "  plt.xlabel('Jumlah cluster')\n",
    "  plt.ylabel('SSE')\n",
    "  plt.title(f'Elbow Food Group {i+1}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Eksperimen dengan berbagai jumlah cluster\n",
    "for k in range(2, 10):\n",
    "  for i, food_scaled in enumerate(foods_scaled) :\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(food_scaled)\n",
    "    silhouette_avg = silhouette_score(food_scaled, kmeans.labels_)\n",
    "    print(f\"For k={k}, the Silhouette Score is {silhouette_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZOtNINKrR18A"
   },
   "outputs": [],
   "source": [
    "# 3 cluster : suggested, alternative, avoid\n",
    "optimal_k = 3\n",
    "\n",
    "for i, food_scaled in enumerate(foods_scaled) :\n",
    "  kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "  clusters = kmeans.fit_predict(food_scaled)\n",
    "  foods_df[i]['Cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "D2-KrjRTSrXt",
    "outputId": "c9a20c03-76c0-4ab8-dc16-3532d3b07650"
   },
   "outputs": [],
   "source": [
    "for i, food_df in enumerate(foods_df) :\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  sns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=food_df, palette='tab10', alpha=0.9, s=100, style='Cluster')\n",
    "\n",
    "  plt.title(f'PCA Visualization Food Group {i+1}')\n",
    "  plt.legend(loc='best')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PD8gkhOTTptg",
    "outputId": "1d054caf-50b5-4382-c174-c1a547727fa2"
   },
   "outputs": [],
   "source": [
    "for i, food_scaled in enumerate(foods_scaled) :\n",
    "  scaler = StandardScaler()\n",
    "  scaler.fit(food_scaled)\n",
    "\n",
    "  cluster_centers = scaler.inverse_transform(kmeans.cluster_centers_)\n",
    "  cluster_df = pd.DataFrame(cluster_centers, columns=food_indices)\n",
    "  cluster_df['Cluster'] = range(optimal_k)\n",
    "\n",
    "  print(cluster_df)\n",
    "\n",
    "  fig, ax = plt.subplots(figsize=(15, 10))\n",
    "  sns.heatmap(cluster_df.set_index('Cluster').T, annot=True, cmap='coolwarm', ax=ax)\n",
    "  plt.title(f'Cluster Centers Food Group {i+1}')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clustering Categorization into Three Categories (Recommended, Safe, and Avoid for Diabetics)**  \n",
    "\n",
    "Here are the steps for interpreting and analyzing the clustering results more deeply:  \n",
    "\n",
    "**1. Heatmap Interpretation**  \n",
    "Based on the heatmap:  \n",
    "- **Cluster 0**: High values in \"Dietary Fiber,\" \"Magnesium,\" and \"Potassium,\" with low values in \"Saturated Fats\" and \"Sugars.\" These correspond to healthy foods with high fiber content.  \n",
    "- **Cluster 1**: Low values in almost all features, except for a slight increase in \"Vitamin D.\" This may represent less nutritious or snack-type foods.  \n",
    "- **Cluster 2**: Very high values in \"Sugars,\" \"Saturated Fats,\" and other fats. This indicates high-calorie, sugary foods unsuitable for diabetics.  \n",
    "\n",
    "**2. Cluster Categorization**  \n",
    "- **Cluster 0 (Recommended)**: Foods with high fiber, low sugar, and low saturated fats. Suitable for everyone, including diabetics.  \n",
    "- **Cluster 1 (Safe for Diabetics)**: Foods with moderate or neutral nutritional values, without high sugar or fat content. Safe for diabetics but not particularly nutrient-dense.  \n",
    "- **Cluster 2 (Avoid for Diabetics)**: Foods high in sugar and saturated fats, and low in fiber. These are unsuitable for diabetics as they can elevate blood sugar levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PUh2uSVoahA2",
    "outputId": "ccf61342-240b-4ede-8b04-98914a3977fa"
   },
   "outputs": [],
   "source": [
    "for clust in range(0, optimal_k) :\n",
    "  print(f\"List of cluster {clust}\")\n",
    "  for i, food_df in enumerate(foods_df) :\n",
    "    print(f\"\\nFood Group {i+1}\")\n",
    "    print(food_df[food_df['Cluster'] == clust]['food'].head(10))\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2WYakcLkPvb"
   },
   "source": [
    "### Save The Clustered Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hGuGscnskU4I"
   },
   "outputs": [],
   "source": [
    "# making clusters data\n",
    "clusters_df = []\n",
    "for i in range(0, optimal_k) :\n",
    "  if len(clusters_df) == i :\n",
    "    clusters_df.append([])\n",
    "\n",
    "  clusters_df[i] = foods_df[0][foods_df[0][\"Cluster\"] == i]\n",
    "\n",
    "for i in range(0, optimal_k) :\n",
    "  for j in range(1, len(foods_df)) :\n",
    "    clusters_df[i] = pd.concat([clusters_df[i], foods_df[j][foods_df[j][\"Cluster\"] == i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 583
    },
    "id": "JcJFaOItlkd1",
    "outputId": "717cd637-4816-474f-a348-0b4b72d90d7e"
   },
   "outputs": [],
   "source": [
    "# print the data\n",
    "for i in range(0, len(clusters_df)) :\n",
    "  print(f\"Cluster {i+1} length: {len(clusters_df[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YeXJPsybmK68"
   },
   "outputs": [],
   "source": [
    "# clean some features\n",
    "for i in range(0, len(clusters_df)) :\n",
    "  clusters_df[i].drop(columns=['Cluster', 'PCA1', 'PCA2', 'Total_Nutrition', 'Nutrition_Density',\n",
    "    'Protein_Ratio', 'Carbohydrate_Ratio', 'Fat_Ratio',\n",
    "    'Nutrient_to_Calorie', 'Fiber_to_Sugar_Ratio', 'Saturated_Fat_Ratio', 'Micronutrient_Sum'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwByKWhcm9UE"
   },
   "outputs": [],
   "source": [
    "# Directory for saving cluster data\n",
    "cluster_dir = \"clustered_food\"\n",
    "os.makedirs(cluster_dir, exist_ok=True)\n",
    "\n",
    "# Ensure unique \"train\" folder names\n",
    "num_train = 0\n",
    "while os.path.exists(f\"{cluster_dir}/train{num_train}\"):\n",
    "  num_train += 1\n",
    "train_folder = f\"{cluster_dir}/train{num_train}\"\n",
    "os.makedirs(train_folder)\n",
    "\n",
    "# Save each cluster's data to CSV files\n",
    "for i, cluster_df in enumerate(clusters_df):\n",
    "  cluster_file = f\"{train_folder}/cluster_{i}.csv\"\n",
    "  cluster_df.to_csv(cluster_file, index=False)\n",
    "\n",
    "print(f\"Cluster data saved in '{cluster_dir}'\")\n",
    "print(f\"Unique train folder created: '{train_folder}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfryIfocye-D"
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "raw_dir_base = f\"{cluster_dir}/raw\"\n",
    "\n",
    "# Ensure unique \"raw\" folder names\n",
    "num_raw = 0\n",
    "while os.path.exists(f\"{raw_dir_base}{num_raw}\"):\n",
    "    num_raw += 1\n",
    "raw_dir = f\"{raw_dir_base}{num_raw}\"\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "\n",
    "# Save each food group's data to CSV files\n",
    "for i, food_df in enumerate(foods_df):\n",
    "    food_file = f\"{raw_dir}/food_group_{i+1}.csv\"\n",
    "    food_df.to_csv(food_file, index=False)\n",
    "\n",
    "print(f\"Food group data saved in '{raw_dir}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8rjr_1Orm_-z",
    "outputId": "b587c252-0e3d-48c6-e3d8-7a733ba407b7"
   },
   "outputs": [],
   "source": [
    "# Optional\n",
    "!zip -r clustered_food.zip clustered_food"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Tags of Food Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'clustered_food/train1'\n",
    "\n",
    "# List to hold the dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over all the files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"cluster\") and filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        # Read the CSV file and append to the list\n",
    "        df = pd.read_csv(file_path)\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "combined_df = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all food name\n",
    "combined_food = \" \".join([i for i in combined_df.food.to_list()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all word in food name\n",
    "food_tags = [i for i in combined_food.split(\" \") if i != \"with\" or i != \"in\" or i != \"on\" or i != \"side\" or i != \"eyed\" or i != \"dish\"]\n",
    "\n",
    "# change the data to set, to prevent duplicate word\n",
    "food_tags = set(food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(food_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SetEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, set):\n",
    "            return list(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "data_tags = json.dumps(food_tags, cls=SetEncoder)\n",
    "print(data_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('food_tags.json', 'w') as f:\n",
    "    json.dump(data_tags, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Top 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_tags = CountVectorizer(max_features=250)\n",
    "\n",
    "vector_tags.fit_transform(combined_df.food)\n",
    "\n",
    "top_250_tags = vector_tags.get_feature_names_out()\n",
    "\n",
    "top_250_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('top_250_tags.json', 'w') as f:\n",
    "    json.dump(list(top_250_tags), f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
